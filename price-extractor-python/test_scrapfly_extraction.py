#!/usr/bin/env python3
"""
Test complete price extraction with Scrapfly for ComMarker
"""
import asyncio
import os
from services.price_service import PriceService
from scrapers.hybrid_web_scraper import get_hybrid_scraper
from scrapers.price_extractor import PriceExtractor
from loguru import logger

async def test_commarker_extraction():
    """Test full price extraction for ComMarker B6 MOPA"""
    print("ðŸŽ¯ Testing ComMarker B6 MOPA Price Extraction with Scrapfly")
    print("=" * 60)
    
    # Test data
    machine_name = "ComMarker B6 MOPA 60W"
    url = "https://commarker.com/product/commarker-b6-jpt-mopa/"
    
    try:
        # Initialize components
        scraper = get_hybrid_scraper()
        extractor = PriceExtractor()
        
        print(f"ðŸ” Machine: {machine_name}")
        print(f"ðŸ”— URL: {url}")
        
        # Verify Scrapfly routing
        should_use_scrapfly = scraper.scrapfly_service and scraper.scrapfly_service.should_use_scrapfly(url)
        print(f"ðŸ“¡ Using Scrapfly: {should_use_scrapfly}")
        
        # Check if extractor recognizes it as Scrapfly site
        is_scrapfly_site = extractor._is_scrapfly_site(url)
        print(f"ðŸ¤– PriceExtractor recognizes as Scrapfly site: {is_scrapfly_site}")
        
        print(f"\nðŸš€ Fetching page content...")
        
        # Fetch content with hybrid scraper
        html_content, soup = await scraper.get_page_content(url)
        
        if html_content and soup:
            print(f"âœ… Page fetched: {len(html_content):,} characters")
            print(f"ðŸ“„ Title: {soup.title.string if soup.title else 'No title'}")
            
            print(f"\nðŸ’° Extracting price...")
            
            # Extract price (should skip browser pool for Scrapfly sites)
            price, method = await extractor.extract_price(
                soup=soup,
                html_content=html_content, 
                url=url,
                machine_name=machine_name,
                old_price=3059.0
            )
            
            if price:
                print(f"âœ… SUCCESS: Price extracted: ${price}")
                print(f"ðŸ”§ Method used: {method}")
                
                # Validate result
                if price > 1000 and price < 10000:
                    print(f"âœ… Price seems reasonable for this machine")
                else:
                    print(f"âš ï¸ Price seems unusual: ${price}")
                    
            else:
                print(f"âŒ FAILED: No price extracted")
                
        else:
            print(f"âŒ Failed to fetch page content")
            
    except Exception as e:
        print(f"âŒ Error: {str(e)}")
        import traceback
        traceback.print_exc()

async def test_xtool_extraction():
    """Test xTool S1 extraction with Scrapfly"""
    print(f"\nðŸŽ¯ Testing xTool S1 Price Extraction with Scrapfly")
    print("=" * 60)
    
    machine_name = "xTool S1"
    url = "https://www.xtool.com/products/xtool-s1-laser-cutter"
    
    try:
        scraper = get_hybrid_scraper()
        extractor = PriceExtractor()
        
        print(f"ðŸ” Machine: {machine_name}")
        print(f"ðŸ”— URL: {url}")
        
        # Check routing
        should_use_scrapfly = scraper.scrapfly_service and scraper.scrapfly_service.should_use_scrapfly(url)
        is_scrapfly_site = extractor._is_scrapfly_site(url)
        
        print(f"ðŸ“¡ Using Scrapfly: {should_use_scrapfly}")
        print(f"ðŸ¤– PriceExtractor recognizes as Scrapfly site: {is_scrapfly_site}")
        
        print(f"\nðŸš€ Fetching page content...")
        
        html_content, soup = await scraper.get_page_content(url)
        
        if html_content and soup:
            print(f"âœ… Page fetched: {len(html_content):,} characters")
            
            print(f"\nðŸ’° Extracting price...")
            
            price, method = await extractor.extract_price(
                soup=soup,
                html_content=html_content,
                url=url, 
                machine_name=machine_name,
                old_price=1999.0
            )
            
            if price:
                print(f"âœ… SUCCESS: Price extracted: ${price}")
                print(f"ðŸ”§ Method used: {method}")
            else:
                print(f"âŒ FAILED: No price extracted")
                
        else:
            print(f"âŒ Failed to fetch page content")
            
    except Exception as e:
        print(f"âŒ Error: {str(e)}")

async def main():
    """Run extraction tests"""
    api_key = os.getenv('SCRAPFLY_API_KEY')
    if not api_key:
        print("âŒ Scrapfly API key not found")
        return
    
    print(f"âœ… Scrapfly API key: {api_key[:10]}...")
    
    await test_commarker_extraction()
    await test_xtool_extraction()
    
    print(f"\nðŸŽ‰ Tests completed!")
    print(f"ðŸ” Check logs above - should see 'METHOD 1 SKIPPED: Scrapfly site' for both tests")

if __name__ == "__main__":
    asyncio.run(main())